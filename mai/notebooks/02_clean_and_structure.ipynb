{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56690f92-1f2f-4ff5-86d5-68dd75bf7540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "\n",
    "input_dir = Path(\"../context/life_with_hope/extracted_text\")\n",
    "output_file = Path(\"../context/life_with_hope/structured/steps.json\")\n",
    "output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Same ranges used before\n",
    "step_page_ranges = {\n",
    "    1: (23, 26),\n",
    "    2: (27, 32),\n",
    "    3: (33, 36),\n",
    "    4: (37, 42),\n",
    "    5: (43, 46),\n",
    "    6: (47, 52),\n",
    "    7: (53, 58),\n",
    "    8: (59, 64),\n",
    "    9: (65, 70),\n",
    "    10: (71, 76),\n",
    "    11: (77, 84),\n",
    "    12: (85, 88),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc2a38c8-712f-4900-81d8-e0d3fa14aa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_step_text(step_num, raw_text):\n",
    "    # Normalize whitespace and remove empty lines\n",
    "    raw = \" \".join([line.strip() for line in raw_text.strip().splitlines() if line.strip()])\n",
    "\n",
    "    # Setup step name\n",
    "    step_word = [\n",
    "        \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\",\n",
    "        \"Seven\", \"Eight\", \"Nine\", \"Ten\", \"Eleven\", \"Twelve\"\n",
    "    ][step_num - 1]\n",
    "    step_pattern = rf\"\\bStep {step_word}\\b\"\n",
    "\n",
    "    # Find where the actual step text starts (after 2nd \"Step X\")\n",
    "    matches = list(re.finditer(step_pattern, raw, flags=re.IGNORECASE))\n",
    "    if len(matches) < 2:\n",
    "        raise ValueError(f\"Could not find two 'Step {step_word}' occurrences in step {step_num}.\")\n",
    "    start_pos = matches[1].end()\n",
    "    body = raw[start_pos:].strip()\n",
    "\n",
    "    # Remove header/footer artifacts like: \"1 Life with Hope Step One 2\"\n",
    "    stitch_pattern = rf\"\\b\\d+\\s+Life with Hope\\s+Step {step_word}\\s+\\d+\\b\"\n",
    "    body = re.sub(stitch_pattern, \"\", body, flags=re.IGNORECASE)\n",
    "\n",
    "    # Also remove simpler artifacts like: \"Life with Hope Step One 4\"\n",
    "    mini_stitch_pattern = rf\"Life with Hope\\s+Step {step_word}\\s+\\d+\"\n",
    "    body = re.sub(mini_stitch_pattern, \"\", body, flags=re.IGNORECASE)\n",
    "\n",
    "    # Extract the first sentence as the title\n",
    "    title_match = re.match(r\"(.*?[.?!])\\s\", body)\n",
    "    title = title_match.group(1).strip() if title_match else \"\"\n",
    "\n",
    "    # Final cleaning pass: normalize whitespace\n",
    "    cleaned = re.sub(r\"\\s+\", \" \", body).strip()\n",
    "\n",
    "    # Attempt to fix common curly-quote encoding artifacts\n",
    "    def fix_unicode_artifacts(text):\n",
    "        try:\n",
    "            return text.encode(\"latin1\").decode(\"utf-8\")\n",
    "        except Exception:\n",
    "            return text\n",
    "\n",
    "    title = fix_unicode_artifacts(title)\n",
    "    cleaned = fix_unicode_artifacts(cleaned)\n",
    "\n",
    "    return {\n",
    "        \"step\": step_num,\n",
    "        \"title\": title,\n",
    "        \"text\": cleaned,\n",
    "        \"tags\": [f\"step_{step_num}\"],\n",
    "        \"source\": \"Life with Hope\",\n",
    "        \"page_start\": step_page_ranges[step_num][0],\n",
    "        \"page_end\": step_page_ranges[step_num][1],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc3c2176-4f8e-4cd6-9f63-81a50b766add",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_steps = []\n",
    "\n",
    "for step_num in range(1, 13):\n",
    "    file_path = input_dir / f\"step_{str(step_num).zfill(2)}.txt\"\n",
    "    if not file_path.exists():\n",
    "        print(f\"❌ Missing: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    raw_text = file_path.read_text(encoding=\"utf-8\")\n",
    "    parsed = parse_step_text(step_num, raw_text)\n",
    "    structured_steps.append(parsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84695b46-9dbb-46f5-af92-f2090595e2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 12 steps to ../context/life_with_hope/structured/steps.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for step in structured_steps:\n",
    "        f.write(json.dumps(step, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"✅ Saved {len(structured_steps)} steps to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e0dad07-5a47-484f-ae3b-e623d28f9d56",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'steps.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load the JSON file\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msteps.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      5\u001b[39m     steps_data = [json.loads(line) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f \u001b[38;5;28;01mif\u001b[39;00m line.strip()]\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Initialize total character count\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py:325\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    320\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'steps.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "with open(\"steps.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    steps_data = [json.loads(line) for line in f if line.strip()]\n",
    "\n",
    "# Initialize total character count\n",
    "total_chars = 0\n",
    "\n",
    "# Analyze each step\n",
    "for step in steps_data:\n",
    "    text = step[\"text\"]\n",
    "    char_count = len(text)\n",
    "    total_chars += char_count\n",
    "    \n",
    "    # Tokenize into words for first and last\n",
    "    words = text.strip().split()\n",
    "    first_word = words[0] if words else \"\"\n",
    "    last_word = words[-1] if words else \"\"\n",
    "\n",
    "    print(f\"Step {step['step']}:\")\n",
    "    print(f\"  Characters: {char_count}\")\n",
    "    print(f\"  First word: {first_word}\")\n",
    "    print(f\"  Last word:  {last_word}\")\n",
    "    print()\n",
    "\n",
    "# Print total\n",
    "print(f\"Total characters across all steps: {total_chars}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd763142-6e1b-4bac-af62-49d7104b147c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
