{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56690f92-1f2f-4ff5-86d5-68dd75bf7540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "\n",
    "input_dir = Path(\"../context/life_with_hope/extracted_text\")\n",
    "output_file = Path(\"../context/life_with_hope/structured/steps.json\")\n",
    "output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Same ranges used before\n",
    "step_page_ranges = {\n",
    "    1: (23, 26),\n",
    "    2: (27, 32),\n",
    "    3: (33, 36),\n",
    "    4: (37, 42),\n",
    "    5: (43, 46),\n",
    "    6: (47, 52),\n",
    "    7: (53, 58),\n",
    "    8: (59, 64),\n",
    "    9: (65, 70),\n",
    "    10: (71, 76),\n",
    "    11: (77, 84),\n",
    "    12: (85, 88),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc2a38c8-712f-4900-81d8-e0d3fa14aa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_step_text(step_num, raw_text):\n",
    "    # Normalize whitespace and remove empty lines\n",
    "    raw = \" \".join([line.strip() for line in raw_text.strip().splitlines() if line.strip()])\n",
    "\n",
    "    # Setup step name\n",
    "    step_word = [\n",
    "        \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\",\n",
    "        \"Seven\", \"Eight\", \"Nine\", \"Ten\", \"Eleven\", \"Twelve\"\n",
    "    ][step_num - 1]\n",
    "    step_pattern = rf\"\\bStep {step_word}\\b\"\n",
    "\n",
    "    # Find where the actual step text starts (after 2nd \"Step X\")\n",
    "    matches = list(re.finditer(step_pattern, raw, flags=re.IGNORECASE))\n",
    "    if len(matches) < 2:\n",
    "        raise ValueError(f\"Could not find two 'Step {step_word}' occurrences in step {step_num}.\")\n",
    "    start_pos = matches[1].end()\n",
    "    body = raw[start_pos:].strip()\n",
    "\n",
    "    # Remove header/footer artifacts like: \"1 Life with Hope Step One 2\"\n",
    "    stitch_pattern = rf\"\\b\\d+\\s+Life with Hope\\s+Step {step_word}\\s+\\d+\\b\"\n",
    "    body = re.sub(stitch_pattern, \"\", body, flags=re.IGNORECASE)\n",
    "\n",
    "    # Also remove simpler artifacts like: \"Life with Hope Step One 4\"\n",
    "    mini_stitch_pattern = rf\"Life with Hope\\s+Step {step_word}\\s+\\d+\"\n",
    "    body = re.sub(mini_stitch_pattern, \"\", body, flags=re.IGNORECASE)\n",
    "\n",
    "    # Extract the first sentence as the title\n",
    "    title_match = re.match(r\"(.*?[.?!])\\s\", body)\n",
    "    title = title_match.group(1).strip() if title_match else \"\"\n",
    "\n",
    "    # Final cleaning pass: normalize whitespace\n",
    "    cleaned = re.sub(r\"\\s+\", \" \", body).strip()\n",
    "\n",
    "    # Attempt to fix common curly-quote encoding artifacts\n",
    "    def fix_unicode_artifacts(text):\n",
    "        try:\n",
    "            return text.encode(\"latin1\").decode(\"utf-8\")\n",
    "        except Exception:\n",
    "            return text\n",
    "\n",
    "    title = fix_unicode_artifacts(title)\n",
    "    cleaned = fix_unicode_artifacts(cleaned)\n",
    "\n",
    "    return {\n",
    "        \"step\": step_num,\n",
    "        \"title\": title,\n",
    "        \"text\": cleaned,\n",
    "        \"tags\": [f\"step_{step_num}\"],\n",
    "        \"source\": \"Life with Hope\",\n",
    "        \"page_start\": step_page_ranges[step_num][0],\n",
    "        \"page_end\": step_page_ranges[step_num][1],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc3c2176-4f8e-4cd6-9f63-81a50b766add",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_steps = []\n",
    "\n",
    "for step_num in range(1, 13):\n",
    "    file_path = input_dir / f\"step_{str(step_num).zfill(2)}.txt\"\n",
    "    if not file_path.exists():\n",
    "        print(f\"❌ Missing: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    raw_text = file_path.read_text(encoding=\"utf-8\")\n",
    "    parsed = parse_step_text(step_num, raw_text)\n",
    "    structured_steps.append(parsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84695b46-9dbb-46f5-af92-f2090595e2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 12 steps to ../context/life_with_hope/structured/steps.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for step in structured_steps:\n",
    "        f.write(json.dumps(step, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"✅ Saved {len(structured_steps)} steps to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e0dad07-5a47-484f-ae3b-e623d28f9d56",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 2 column 1 (char 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Load the JSON file\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     steps_data = [\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f \u001b[38;5;28;01mif\u001b[39;00m line.strip()]\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Initialize total character count\u001b[39;00m\n\u001b[32m     11\u001b[39m total_chars = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/json/decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    333\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m     end = _w(s, end).end()\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/json/decoder.py:353\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    344\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[33;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[33;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    350\u001b[39m \n\u001b[32m    351\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting property name enclosed in double quotes: line 2 column 1 (char 2)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Correct relative path to your file\n",
    "file_path = \"../context/life_with_hope/structured/steps.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    steps_data = [json.loads(line) for line in f if line.strip()]\n",
    "\n",
    "# Initialize total character count\n",
    "total_chars = 0\n",
    "\n",
    "# Analyze each step\n",
    "for step in steps_data:\n",
    "    text = step[\"text\"]\n",
    "    char_count = len(text)\n",
    "    total_chars += char_count\n",
    "\n",
    "    # Tokenize into words for first and last\n",
    "    words = text.strip().split()\n",
    "    first_word = words[0] if words else \"\"\n",
    "    last_word = words[-1] if words else \"\"\n",
    "\n",
    "    print(f\"Step {step['step']}:\")\n",
    "    print(f\"  Characters: {char_count}\")\n",
    "    print(f\"  First word: {first_word}\")\n",
    "    print(f\"  Last word:  {last_word}\")\n",
    "    print()\n",
    "\n",
    "# Print total\n",
    "print(f\"Total characters across all steps: {total_chars}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd763142-6e1b-4bac-af62-49d7104b147c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/llm-zoomcamp/mai/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38023e6d-c66e-4313-b52e-31fbb438203e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
