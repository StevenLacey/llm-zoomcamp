{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a07922d7",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9a381677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\")) # Get Key from Env (ignored in git) \n",
    "client = OpenAI()\n",
    "from elasticsearch import Elasticsearch\n",
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "from tqdm.auto import tqdm\n",
    "import fitz  # PyMuPDF\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ac63a72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/llm-zoomcamp/mai/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a8d630",
   "metadata": {},
   "source": [
    "## Load documents in good format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fdde92e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../context/life_with_hope/structured/steps.json', 'r') as f: \n",
    "    steps = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc345cca",
   "metadata": {},
   "source": [
    "## Create Index Settings for Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5882d5",
   "metadata": {},
   "source": [
    "### Note: Looks like persists so trips an error if recreating in same instance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b46c9f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'life-with-hope-steps'})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"step\":        {\"type\": \"integer\"},\n",
    "            \"title\":       {\"type\": \"text\"},\n",
    "            \"text\":        {\"type\": \"text\"},\n",
    "            \"source\":      {\"type\": \"keyword\"},\n",
    "            \"page_start\":  {\"type\": \"integer\"},\n",
    "            \"page_end\":    {\"type\": \"integer\"},\n",
    "            \"tags\":        {\"type\": \"keyword\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"life-with-hope-steps\"\n",
    "\n",
    "# Create the index (will error if it already exists)\n",
    "es_client.indices.create(index=index_name, body=index_settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e22ee38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# innitialize the conversation history \n",
    "current_conversation_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b60eb53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get spiritual explorer persona\n",
    "def get_spiritual_explorer_persona():\n",
    "    \"\"\"Get the spiritual_explorer persona specifically\"\"\"\n",
    "    with open('../context/personas/personas.json', 'r') as f:\n",
    "        personas = json.load(f)\n",
    "    return next(p for p in personas if p['persona_id'] == 'spiritual_explorer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83416242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG and Prompt Functions\n",
    "def build_initial_conversation_prompt(query, conversation_history=None):\n",
    "    \"\"\"Build prompt for initial conversation using spiritual_explorer persona from JSON\"\"\"\n",
    "    \n",
    "    # Get spiritual_explorer persona from file\n",
    "    persona = get_spiritual_explorer_persona()\n",
    "    \n",
    "    # Build conversation context if history exists\n",
    "    history_text = \"\"\n",
    "    if conversation_history:\n",
    "        recent_history = conversation_history[-4:]  # Last 2 exchanges\n",
    "        for msg in recent_history:\n",
    "            role = \"User\" if msg[\"role\"] == \"user\" else \"Sponsor\"\n",
    "            history_text += f\"{role}: {msg['content']}\\n\"\n",
    "        history_text = f\"\\nRecent conversation:\\n{history_text}\"\n",
    "    \n",
    "    prompt_template = f\"\"\"You are an experienced MA sponsor meeting someone for their very first time at Marijuana Anonymous.\n",
    "\n",
    "Your communication style: {persona['language_style']} \n",
    "Your approach: {persona['description']}\n",
    "\n",
    "This is an initial meeting conversation. Your goals:\n",
    "1. Welcome them warmly and create a safe space\n",
    "2. Learn their name\n",
    "3. Understand what brought them to MA today  \n",
    "4. Gently assess their relationship with marijuana\n",
    "5. Begin to understand their spiritual openness (without being pushy)\n",
    "6. Determine if they're ready to start recovery work\n",
    "\n",
    "Keep responses conversational and warm (2-3 sentences max). Don't rush through questions - let the conversation flow naturally.{history_text}\n",
    "\n",
    "User says: \"{query}\"\n",
    "\n",
    "Respond as their sponsor:\"\"\"\n",
    "    \n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c1784d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_initial(prompt, model=\"gpt-4o\"):\n",
    "    \"\"\"LLM call for initial conversations\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a warm, experienced MA sponsor. Keep responses natural and conversational.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50285680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_initial_conversation(query, conversation_history=None):\n",
    "    \"\"\"RAG function for initial conversations\"\"\"\n",
    "    prompt = build_initial_conversation_prompt(query, conversation_history)\n",
    "    answer = llm_initial(prompt)\n",
    "    # Update conversation history\n",
    "    current_conversation_history.append({\"sender\": \"user\", \"content\": query})\n",
    "    current_conversation_history.append({\"sender\": \"ai_sponsor\", \"content\": answer})\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71d8c1d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "52067fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I completely understand. It's all about taking things one step at a time, and I'm here whenever you're ready to explore further. Take care, and I'll be here when you're ready for another chat. See you around!\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_initial_conversation(\"I used to be a believe. now i dont know. but anyways i gotta go man. see you around\",conversation_history=current_conversation_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8dae024a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824fcd13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
