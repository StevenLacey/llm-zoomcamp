{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53164811-38f3-46c5-9041-8fa9df9f6c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 5 files: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array shape: (512,)\n",
      "Array size: 512\n",
      "Minimum value: -0.11726373885183883\n",
      "\n",
      "Array statistics:\n",
      "Min: -0.11726373885183883\n",
      "Max: 0.13307955818198478\n",
      "Mean: -0.0007128863462480066\n",
      "Std: 0.04418842374488293\n"
     ]
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the embedding model\n",
    "model = TextEmbedding(\"jinaai/jina-embeddings-v2-small-en\")\n",
    "\n",
    "# Embed the query\n",
    "query = \"I just discovered the course. Can I join now?\"\n",
    "embeddings = list(model.embed([query]))\n",
    "\n",
    "# Get the embedding array\n",
    "embedding_array = embeddings[0]\n",
    "\n",
    "# Convert to numpy array if it isn't already\n",
    "embedding_array = np.array(embedding_array)\n",
    "\n",
    "print(f\"Array shape: {embedding_array.shape}\")\n",
    "print(f\"Array size: {embedding_array.size}\")\n",
    "print(f\"Minimum value: {embedding_array.min()}\")\n",
    "\n",
    "# Show some statistics\n",
    "print(f\"\\nArray statistics:\")\n",
    "print(f\"Min: {embedding_array.min()}\")\n",
    "print(f\"Max: {embedding_array.max()}\")\n",
    "print(f\"Mean: {embedding_array.mean()}\")\n",
    "print(f\"Std: {embedding_array.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10278cdf-bd40-4b55-aabb-73f3a1ed6626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query vector shape: (512,)\n",
      "Document vector shape: (512,)\n",
      "\n",
      "Cosine similarity: 0.9008528895674548\n",
      "Rounded to 1 decimal place: 0.9\n",
      "\n",
      "Query vector norm: 1.0\n",
      "Document vector norm: 1.0\n"
     ]
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the embedding model\n",
    "model = TextEmbedding(\"jinaai/jina-embeddings-v2-small-en\")\n",
    "\n",
    "# Embed both texts\n",
    "query = \"I just discovered the course. Can I join now?\"\n",
    "doc = \"Can I still join the course after the start date?\"\n",
    "\n",
    "# Get embeddings for both\n",
    "embeddings = list(model.embed([query, doc]))\n",
    "\n",
    "# Convert to numpy arrays\n",
    "query_vector = np.array(embeddings[0])\n",
    "doc_vector = np.array(embeddings[1])\n",
    "\n",
    "print(f\"Query vector shape: {query_vector.shape}\")\n",
    "print(f\"Document vector shape: {doc_vector.shape}\")\n",
    "\n",
    "# Calculate cosine similarity using dot product (since vectors are already normalized)\n",
    "cosine_similarity = np.dot(query_vector, doc_vector)\n",
    "\n",
    "print(f\"\\nCosine similarity: {cosine_similarity}\")\n",
    "print(f\"Rounded to 1 decimal place: {round(cosine_similarity, 1)}\")\n",
    "\n",
    "# Verify that vectors are normalized (length should be 1.0)\n",
    "query_norm = np.linalg.norm(query_vector)\n",
    "doc_norm = np.linalg.norm(doc_vector)\n",
    "print(f\"\\nQuery vector norm: {query_norm}\")\n",
    "print(f\"Document vector norm: {doc_norm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd73a43c-57c9-42dd-8648-17afe581a693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: I just discovered the course. Can I join now?\n",
      "Number of documents: 5\n",
      "Document 0: similarity = 0.7630\n",
      "  Question: Course - Can I still join the course after the start date?\n",
      "\n",
      "Document 1: similarity = 0.8182\n",
      "  Question: Course - Can I follow the course after it finishes?\n",
      "\n",
      "Document 2: similarity = 0.8085\n",
      "  Question: Course - When will the course start?\n",
      "\n",
      "Document 3: similarity = 0.7133\n",
      "  Question: Course - What can I do before the course starts?\n",
      "\n",
      "Document 4: similarity = 0.7304\n",
      "  Question: How can we contribute to the course?\n",
      "\n",
      "Document with highest similarity:\n",
      "Index: 1\n",
      "Similarity: 0.8182\n",
      "Question: Course - Can I follow the course after it finishes?\n"
     ]
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the embedding model\n",
    "model = TextEmbedding(\"jinaai/jina-embeddings-v2-small-en\")\n",
    "\n",
    "# The query from Q1\n",
    "query = \"I just discovered the course. Can I join now?\"\n",
    "\n",
    "# The documents\n",
    "documents = [{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I still join the course after the start date?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I follow the course after it finishes?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - When will the course start?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - What can I do before the course starts?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'How can we contribute to the course?',\n",
    "  'course': 'data-engineering-zoomcamp'}]\n",
    "\n",
    "# Extract just the text field from documents\n",
    "document_texts = [doc['text'] for doc in documents]\n",
    "\n",
    "# Create a list with query + all document texts for embedding\n",
    "all_texts = [query] + document_texts\n",
    "\n",
    "# Get embeddings for all texts\n",
    "embeddings = list(model.embed(all_texts))\n",
    "\n",
    "# Convert to numpy arrays\n",
    "query_vector = np.array(embeddings[0])  # First embedding is the query\n",
    "document_vectors = [np.array(emb) for emb in embeddings[1:]]  # Rest are documents\n",
    "\n",
    "print(\"Query:\", query)\n",
    "print(f\"Number of documents: {len(document_vectors)}\")\n",
    "\n",
    "# Calculate cosine similarities\n",
    "similarities = []\n",
    "for i, doc_vector in enumerate(document_vectors):\n",
    "    similarity = np.dot(query_vector, doc_vector)\n",
    "    similarities.append(similarity)\n",
    "    print(f\"Document {i}: similarity = {similarity:.4f}\")\n",
    "    print(f\"  Question: {documents[i]['question']}\")\n",
    "    print()\n",
    "\n",
    "# Find the document with highest similarity\n",
    "max_similarity_index = np.argmax(similarities)\n",
    "max_similarity_value = similarities[max_similarity_index]\n",
    "\n",
    "print(f\"Document with highest similarity:\")\n",
    "print(f\"Index: {max_similarity_index}\")\n",
    "print(f\"Similarity: {max_similarity_value:.4f}\")\n",
    "print(f\"Question: {documents[max_similarity_index]['question']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f05d0622-caa1-4630-8dac-cdc5e2874f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 combined text:\n",
      "Question: Course - Can I still join the course after the start date?\n",
      "Combined: Course - Can I still join the course after the start date? Yes, even if you don't register, you're s...\n",
      "\n",
      "Document 1 combined text:\n",
      "Question: Course - Can I follow the course after it finishes?\n",
      "Combined: Course - Can I follow the course after it finishes? Yes, we will keep all the materials after the co...\n",
      "\n",
      "Document 2 combined text:\n",
      "Question: Course - When will the course start?\n",
      "Combined: Course - When will the course start? The purpose of this document is to capture frequently asked tec...\n",
      "\n",
      "Document 3 combined text:\n",
      "Question: Course - What can I do before the course starts?\n",
      "Combined: Course - What can I do before the course starts? You can start by installing and setting up all the ...\n",
      "\n",
      "Document 4 combined text:\n",
      "Question: How can we contribute to the course?\n",
      "Combined: How can we contribute to the course? Star the repo! Share it with friends if you find it useful ❣️\n",
      "C...\n",
      "\n",
      "=== COSINE SIMILARITIES ===\n",
      "Query: I just discovered the course. Can I join now?\n",
      "\n",
      "Document 0: similarity = 0.8515\n",
      "  Question: Course - Can I still join the course after the start date?\n",
      "\n",
      "Document 1: similarity = 0.8437\n",
      "  Question: Course - Can I follow the course after it finishes?\n",
      "\n",
      "Document 2: similarity = 0.8408\n",
      "  Question: Course - When will the course start?\n",
      "\n",
      "Document 3: similarity = 0.7755\n",
      "  Question: Course - What can I do before the course starts?\n",
      "\n",
      "Document 4: similarity = 0.8086\n",
      "  Question: How can we contribute to the course?\n",
      "\n",
      "=== RESULT ===\n",
      "Document with highest similarity:\n",
      "Index: 0\n",
      "Similarity: 0.8515\n",
      "Question: Course - Can I still join the course after the start date?\n",
      "\n",
      "=== COMPARISON WITH Q3 ===\n",
      "In Q4, we're using question + text (combined)\n",
      "In Q3, we used only the text field\n",
      "This might change the ranking because the question field adds more semantic context\n"
     ]
    }
   ],
   "source": [
    "# Create the new combined field as shown in the formula\n",
    "combined_texts = []\n",
    "for i, doc in enumerate(documents):\n",
    "    full_text = doc['question'] + ' ' + doc['text']\n",
    "    combined_texts.append(full_text)\n",
    "    print(f\"Document {i} combined text:\")\n",
    "    print(f\"Question: {doc['question']}\")\n",
    "    print(f\"Combined: {full_text[:100]}...\")  # Show first 100 chars\n",
    "    print()\n",
    "\n",
    "# Create a list with query + all combined texts for embedding\n",
    "all_texts = [query] + combined_texts\n",
    "\n",
    "# Get embeddings for all texts\n",
    "embeddings = list(model.embed(all_texts))\n",
    "\n",
    "# Convert to numpy arrays\n",
    "query_vector = np.array(embeddings[0])  # First embedding is the query\n",
    "document_vectors = [np.array(emb) for emb in embeddings[1:]]  # Rest are documents\n",
    "\n",
    "print(\"=== COSINE SIMILARITIES ===\")\n",
    "print(\"Query:\", query)\n",
    "print()\n",
    "\n",
    "# Calculate cosine similarities\n",
    "similarities = []\n",
    "for i, doc_vector in enumerate(document_vectors):\n",
    "    similarity = np.dot(query_vector, doc_vector)\n",
    "    similarities.append(similarity)\n",
    "    print(f\"Document {i}: similarity = {similarity:.4f}\")\n",
    "    print(f\"  Question: {documents[i]['question']}\")\n",
    "    print()\n",
    "\n",
    "# Find the document with highest similarity\n",
    "max_similarity_index = np.argmax(similarities)\n",
    "max_similarity_value = similarities[max_similarity_index]\n",
    "\n",
    "print(f\"=== RESULT ===\")\n",
    "print(f\"Document with highest similarity:\")\n",
    "print(f\"Index: {max_similarity_index}\")\n",
    "print(f\"Similarity: {max_similarity_value:.4f}\")\n",
    "print(f\"Question: {documents[max_similarity_index]['question']}\")\n",
    "\n",
    "# Compare with Q3 result\n",
    "print(f\"\\n=== COMPARISON WITH Q3 ===\")\n",
    "print(\"In Q4, we're using question + text (combined)\")\n",
    "print(\"In Q3, we used only the text field\")\n",
    "print(\"This might change the ranking because the question field adds more semantic context\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffabf630-a8a6-49c0-8c78-0cf4ce5ab6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAAI/bge-base-en-v1.5 768\n",
      "BAAI/bge-large-en-v1.5 1024\n",
      "BAAI/bge-small-en 384\n",
      "BAAI/bge-small-en-v1.5 384\n",
      "BAAI/bge-small-zh-v1.5 512\n",
      "mixedbread-ai/mxbai-embed-large-v1 1024\n",
      "snowflake/snowflake-arctic-embed-xs 384\n",
      "snowflake/snowflake-arctic-embed-s 384\n",
      "snowflake/snowflake-arctic-embed-m 768\n",
      "snowflake/snowflake-arctic-embed-m-long 768\n",
      "snowflake/snowflake-arctic-embed-l 1024\n",
      "jinaai/jina-clip-v1 768\n",
      "Qdrant/clip-ViT-B-32-text 512\n",
      "sentence-transformers/all-MiniLM-L6-v2 384\n",
      "jinaai/jina-embeddings-v2-base-en 768\n",
      "jinaai/jina-embeddings-v2-small-en 512\n",
      "jinaai/jina-embeddings-v2-base-de 768\n",
      "jinaai/jina-embeddings-v2-base-code 768\n",
      "jinaai/jina-embeddings-v2-base-zh 768\n",
      "jinaai/jina-embeddings-v2-base-es 768\n",
      "thenlper/gte-base 768\n",
      "thenlper/gte-large 1024\n",
      "nomic-ai/nomic-embed-text-v1.5 768\n",
      "nomic-ai/nomic-embed-text-v1.5-Q 768\n",
      "nomic-ai/nomic-embed-text-v1 768\n",
      "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 384\n",
      "sentence-transformers/paraphrase-multilingual-mpnet-base-v2 768\n",
      "intfloat/multilingual-e5-large 1024\n",
      "jinaai/jina-embeddings-v3 1024\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(TextEmbedding.list_supported_models())): \n",
    "    print(TextEmbedding.list_supported_models()[i]['model'], TextEmbedding.list_supported_models()[i]['dim'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc5d4011-8437-4c55-b857-30f4e62dd661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TextEmbedding.list_supported_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec4d67f-c86a-4036-83a2-39c21d765aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents loaded: 3\n",
      "Documents after filtering for machine-learning-zoomcamp: 375\n",
      "Deleted existing collection: course_questions\n",
      "Created collection: course_questions\n",
      "Prepared 375 texts for embedding\n",
      "Generating embeddings...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from qdrant_client import QdrantClient, models\n",
    "from fastembed import TextEmbedding\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Qdrant client and embedding model\n",
    "client = QdrantClient(\"http://localhost:6333\")\n",
    "model = TextEmbedding(\"jinaai/jina-embeddings-v2-small-en\")\n",
    "\n",
    "# Load the documents\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "print(f\"Total documents loaded: {len(documents_raw)}\")\n",
    "\n",
    "# Filter for machine-learning-zoomcamp and prepare documents\n",
    "documents = []\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "    if course_name != 'machine-learning-zoomcamp':\n",
    "        continue\n",
    "    \n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "print(f\"Documents after filtering for machine-learning-zoomcamp: {len(documents)}\")\n",
    "\n",
    "# Create collection in Qdrant\n",
    "collection_name = \"course_questions\"\n",
    "\n",
    "# Delete collection if it exists (for clean slate)\n",
    "try:\n",
    "    client.delete_collection(collection_name)\n",
    "    print(f\"Deleted existing collection: {collection_name}\")\n",
    "except:\n",
    "    print(f\"Collection {collection_name} didn't exist\")\n",
    "\n",
    "# Create new collection\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(size=512, distance=models.Distance.COSINE),\n",
    ")\n",
    "print(f\"Created collection: {collection_name}\")\n",
    "\n",
    "# Prepare documents for indexing - combine question and text\n",
    "texts_to_embed = []\n",
    "points_data = []\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    # Combine question and text as specified\n",
    "    text = doc['question'] + ' ' + doc['text']\n",
    "    texts_to_embed.append(text)\n",
    "    \n",
    "    # Store document data for later\n",
    "    points_data.append({\n",
    "        'id': i,\n",
    "        'text': text,\n",
    "        'question': doc['question'],\n",
    "        'answer': doc['text'],\n",
    "        'section': doc['section'],\n",
    "        'course': doc['course']\n",
    "    })\n",
    "\n",
    "print(f\"Prepared {len(texts_to_embed)} texts for embedding\")\n",
    "\n",
    "# Get embeddings for all documents\n",
    "print(\"Generating embeddings...\")\n",
    "embeddings = list(model.embed(texts_to_embed))\n",
    "print(f\"Generated {len(embeddings)} embeddings\")\n",
    "\n",
    "# Create points for Qdrant\n",
    "points = []\n",
    "for i, (embedding, data) in enumerate(zip(embeddings, points_data)):\n",
    "    point = models.PointStruct(\n",
    "        id=i,\n",
    "        vector=embedding.tolist(),\n",
    "        payload={\n",
    "            'text': data['text'],\n",
    "            'question': data['question'],\n",
    "            'answer': data['answer'],\n",
    "            'section': data['section'],\n",
    "            'course': data['course']\n",
    "        }\n",
    "    )\n",
    "    points.append(point)\n",
    "\n",
    "# Upload points to Qdrant\n",
    "print(\"Uploading points to Qdrant...\")\n",
    "client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")\n",
    "print(f\"Uploaded {len(points)} points to Qdrant\")\n",
    "\n",
    "# Now query with the question from Q1\n",
    "query = \"I just discovered the course. Can I join now?\"\n",
    "print(f\"\\nQuerying with: {query}\")\n",
    "\n",
    "# Embed the query\n",
    "query_embedding = list(model.embed([query]))[0]\n",
    "\n",
    "# Search in Qdrant\n",
    "search_results = client.search(\n",
    "    collection_name=collection_name,\n",
    "    query_vector=query_embedding.tolist(),\n",
    "    limit=5  # Get top 5 results\n",
    ")\n",
    "\n",
    "print(f\"\\nSearch Results:\")\n",
    "print(f\"Number of results: {len(search_results)}\")\n",
    "\n",
    "for i, result in enumerate(search_results):\n",
    "    print(f\"\\nResult {i+1}:\")\n",
    "    print(f\"Score: {result.score:.4f}\")\n",
    "    print(f\"Question: {result.payload['question']}\")\n",
    "    print(f\"Answer: {result.payload['answer'][:100]}...\")  # First 100 chars\n",
    "\n",
    "# Get the highest score (first result)\n",
    "if search_results:\n",
    "    highest_score = search_results[0].score\n",
    "    print(f\"\\n=== ANSWER ===\")\n",
    "    print(f\"Highest score: {highest_score:.3f}\")\n",
    "    print(f\"Rounded to 2 decimal places: {round(highest_score, 2)}\")\n",
    "else:\n",
    "    print(\"No search results found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b34985-5bcd-4ed8-97fb-c1b46123590a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
